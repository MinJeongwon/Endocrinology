02/24/2023 10:36:08 - INFO - __main__ - Model: bert-base-uncased
02/24/2023 10:36:13 - INFO - data - *** Example ***
02/24/2023 10:36:13 - INFO - data - tokens: [CLS] trajectory patterns for continuous metabolic syndrome score in childhood and the cardiovascular risk in adolescence . [SEP] we explored the association between the trajectory of the continuous metabolic syndrome score ( cm ##ets ) in childhood with high - sensitivity c - reactive protein ( hs - cr ##p ) and car ##ot ##id int ##ima - media thickness ( ci ##mt ) , which are known to increase cardiovascular disease risk in adolescence . the trajectory of cm ##ets in childhood ( from 3 to 12 \ x ##a ##0 ##year ##s of age ) was identified in 83 ##3 children who participated in the e ##w ##ha birth and growth study . the associations between cm ##ets and hs - cr ##p and ci ##mt were analyzed in 204 out of 83 ##3 children who participated in the follow - up at 13 - 15 \ x ##a ##0 ##year ##s of age and measured hs - cr ##p and ci ##mt . among the 83 ##3 children , three groups were classified : cm ##ets maintained at a low level ( n \ u2 ##00 ##9 = \ u2 ##00 ##9 ##19 ##8 , 23 . 77 % ) , middle level ( n \ u2 ##00 ##9 = \ u2 ##00 ##9 ##53 ##0 , 63 . 63 % ) , and at high levels ( n \ u2 ##00 ##9 = \ u2 ##00 ##9 ##10 ##5 , 12 . 61 % ) . the group with a stable - high cm ##ets trajectory showed significantly higher hs - cr ##p levels , and the statistical significance was maintained after adjusting for co ##var ##iate ##s . this study found that a consistently high cm ##ets in childhood was significantly associated with higher hs - cr ##p levels in adolescents , suggesting that it is necessary to intervene in metabolic risk factors early in life to reduce the risk of cardiovascular disease later in life . [SEP]
02/24/2023 10:36:13 - INFO - data - input_ids: 101 22793 7060 2005 7142 21453 8715 3556 1999 5593 1998 1996 22935 3891 1999 29101 1012 102 2057 10641 1996 2523 2090 1996 22793 1997 1996 7142 21453 8715 3556 1006 4642 8454 1007 1999 5593 2007 2152 1011 14639 1039 1011 22643 5250 1006 26236 1011 13675 2361 1007 1998 2482 4140 3593 20014 9581 1011 2865 14983 1006 25022 20492 1007 1010 2029 2024 2124 2000 3623 22935 4295 3891 1999 29101 1012 1996 22793 1997 4642 8454 1999 5593 1006 2013 1017 2000 2260 1032 1060 2050 2692 29100 2015 1997 2287 1007 2001 4453 1999 6640 2509 2336 2040 4194 1999 1996 1041 2860 3270 4182 1998 3930 2817 1012 1996 8924 2090 4642 8454 1998 26236 1011 13675 2361 1998 25022 20492 2020 16578 1999 19627 2041 1997 6640 2509 2336 2040 4194 1999 1996 3582 1011 2039 2012 2410 1011 2321 1032 1060 2050 2692 29100 2015 1997 2287 1998 7594 26236 1011 13675 2361 1998 25022 20492 1012 2426 1996 6640 2509 2336 1010 2093 2967 2020 6219 1024 4642 8454 5224 2012 1037 2659 2504 1006 1050 1032 23343 8889 2683 1027 1032 23343 8889 2683 16147 2620 1010 2603 1012 6255 1003 1007 1010 2690 2504 1006 1050 1032 23343 8889 2683 1027 1032 23343 8889 2683 22275 2692 1010 6191 1012 6191 1003 1007 1010 1998 2012 2152 3798 1006 1050 1032 23343 8889 2683 1027 1032 23343 8889 2683 10790 2629 1010 2260 1012 6079 1003 1007 1012 1996 2177 2007 1037 6540 1011 2152 4642 8454 22793 3662 6022 3020 26236 1011 13675 2361 3798 1010 1998 1996 7778 7784 2001 5224 2044 19158 2005 2522 10755 13143 2015 1012 2023 2817 2179 2008 1037 10862 2152 4642 8454 1999 5593 2001 6022 3378 2007 3020 26236 1011 13675 2361 3798 1999 25947 1010 9104 2008 2009 2003 4072 2000 18793 1999 21453 3891 5876 2220 1999 2166 2000 5547 1996 3891 1997 22935 4295 2101 1999 2166 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:13 - INFO - data - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:13 - INFO - data - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:13 - INFO - data - label: diabetes (id = 1)
02/24/2023 10:36:13 - INFO - data - *** Example ***
02/24/2023 10:36:13 - INFO - data - tokens: [CLS] comparison of four ultra ##son ##ography - based risk st ##rat ##ification systems in thyroid nod ##ules with non ##dia ##gno ##stic / un ##sat ##is ##factory cy ##tology : a real - world study . [SEP] we compared american thyroid association ( ata ) guidelines , korean ( k ) - thyroid imaging , reporting and data systems ( ti ##rad ##s ) , eu - ti ##rad ##s , and american college of radio ##logy ( ac ##r ) ti ##rad ##s in dia ##gno ##sing mali ##gnan ##cy for thyroid nod ##ules with non ##dia ##gno ##stic / un ##sat ##is ##factory cy ##tology . among 114 ##3 non ##dia ##gno ##stic / un ##sat ##is ##factory aspirations from april 2011 to march 2016 , mali ##gnan ##cy was detected in 39 of 89 ex ##cise ##d nod ##ules . the minimum mali ##gnan ##cy rate was 7 . 82 % in eu - ti ##rad ##s 5 and 1 . 87 - 3 . 00 % in eu - ti ##rad ##s 3 - 4 . in the other systems , the minimum mali ##gnan ##cy rate was 14 . 29 - 16 . 19 % in category 5 and ≤ ##3 % in the remaining categories . although the eu - ti ##rad ##s category ≥ 5 exhibited the highest positive likelihood ratio ( l ##r ) of only 2 . 214 , category ≥ 5 in the other systems yielded the highest positive l ##r of > 5 . receiver operating characteristic ( roc ) curves of all systems to predict mali ##gnan ##cy were located statistical ##ly above the diagonal non ##dis ##cr ##imi ##nation line ( p for roc curve : eu - ti ##rad ##s , 0 . 00 ##22 ; all others , 0 . 000 ##1 ) . the areas under the roc curve ( au ##cs ) were not significantly different among the four systems . the ata guidelines , k - ti ##rad ##s , and ac ##r ti ##rad ##s may be useful to guide management for non ##dia ##gno ##stic / un ##sat ##is ##factory nod ##ules . the eu - ti ##rad ##s , although also useful , exhibited inferior performance in predicting mali ##gnan ##cy for non ##dia ##gno ##stic / un ##sat ##is ##factory nod ##ules in korea , an io ##dine - sufficient area . [SEP]
02/24/2023 10:36:13 - INFO - data - input_ids: 101 7831 1997 2176 11087 3385 9888 1011 2241 3891 2358 8609 9031 3001 1999 29610 7293 16308 2007 2512 9032 26745 10074 1013 4895 16846 2483 21450 22330 23479 1024 1037 2613 1011 2088 2817 1012 102 2057 4102 2137 29610 2523 1006 29533 1007 11594 1010 4759 1006 1047 1007 1011 29610 12126 1010 7316 1998 2951 3001 1006 14841 12173 2015 1007 1010 7327 1011 14841 12173 2015 1010 1998 2137 2267 1997 2557 6483 1006 9353 2099 1007 14841 12173 2015 1999 22939 26745 7741 16007 28207 5666 2005 29610 7293 16308 2007 2512 9032 26745 10074 1013 4895 16846 2483 21450 22330 23479 1012 2426 12457 2509 2512 9032 26745 10074 1013 4895 16846 2483 21450 22877 2013 2258 2249 2000 2233 2355 1010 16007 28207 5666 2001 11156 1999 4464 1997 6486 4654 18380 2094 7293 16308 1012 1996 6263 16007 28207 5666 3446 2001 1021 1012 6445 1003 1999 7327 1011 14841 12173 2015 1019 1998 1015 1012 6584 1011 1017 1012 4002 1003 1999 7327 1011 14841 12173 2015 1017 1011 1018 1012 1999 1996 2060 3001 1010 1996 6263 16007 28207 5666 3446 2001 2403 1012 2756 1011 2385 1012 2539 1003 1999 4696 1019 1998 1608 2509 1003 1999 1996 3588 7236 1012 2348 1996 7327 1011 14841 12173 2015 4696 1609 1019 8176 1996 3284 3893 16593 6463 1006 1048 2099 1007 1997 2069 1016 1012 19936 1010 4696 1609 1019 1999 1996 2060 3001 17544 1996 3284 3893 1048 2099 1997 1028 1019 1012 8393 4082 8281 1006 21326 1007 10543 1997 2035 3001 2000 16014 16007 28207 5666 2020 2284 7778 2135 2682 1996 19754 2512 10521 26775 27605 9323 2240 1006 1052 2005 21326 7774 1024 7327 1011 14841 12173 2015 1010 1014 1012 4002 19317 1025 2035 2500 1010 1014 1012 2199 2487 1007 1012 1996 2752 2104 1996 21326 7774 1006 8740 6169 1007 2020 2025 6022 2367 2426 1996 2176 3001 1012 1996 29533 11594 1010 1047 1011 14841 12173 2015 1010 1998 9353 2099 14841 12173 2015 2089 2022 6179 2000 5009 2968 2005 2512 9032 26745 10074 1013 4895 16846 2483 21450 7293 16308 1012 1996 7327 1011 14841 12173 2015 1010 2348 2036 6179 1010 8176 14092 2836 1999 29458 16007 28207 5666 2005 2512 9032 26745 10074 1013 4895 16846 2483 21450 7293 16308 1999 4420 1010 2019 22834 10672 1011 7182 2181 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:13 - INFO - data - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:13 - INFO - data - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:13 - INFO - data - label: thyroid (id = 4)
02/24/2023 10:36:21 - INFO - __main__ - Label Encoding: ['bone' 'diabetes' 'others' 'pitu/adrenal' 'thyroid' 'x']-->[0 1 2 3 4 5]
02/24/2023 10:36:26 - INFO - data - *** Example ***
02/24/2023 10:36:26 - INFO - data - tokens: [CLS] changes in trim ##eth ##yla ##mine - n - oxide levels in obe ##se patients following lap ##aro ##scopic ro ##ux - en - y gas ##tric bypass or sleeve gas ##tre ##ct ##omy in a korean obesity surgical treatment study ( kobe ##ss ) . [SEP] rd ##ered ##dict ( [ ( ' su ##p ' , [ ' 2 ' , ' 2 ' ] ) , ( ' # text ' , ' trim ##eth ##yla ##mine n - oxide ( t ##ma ##o ) , a gut micro ##be - dependent meta ##bol ##ite , has been implicated as a novel risk factor for cardiovascular events related to obesity and type 2 diabetes mel ##lit ##us ( t ##2 ##dm ) . the aim of the study was to test the hypothesis if t ##ma ##o is associated with the reduction of cardiovascular disease in the korean obe ##se patients who underwent bari ##at ##ric surgery . from a subgroup of a multi ##cent ##er , non ##rand ##omi ##zed , controlled trial , titled kobe ##ss , 38 obe ##se patients , 18 with and 20 without t ##2 ##dm , who underwent ro ##ux - en - y gas ##tric bypass ( ry ##gb ) or sleeve gas ##tre ##ct ##omy ( sg ) were investigated . bari ##at ##ric surgery is indicated for korean patients with a body mass index ( b ##mi ) ≥ 35 kg / m or for korean patients with a b ##mi ≥ 30 kg / m who have como ##rb ##idi ##ties . serum levels of t ##ma ##o and its precursor ##s , beta ##ine , car ##ni ##tine , and cho ##line were measured before and six months after bari ##at ##ric surgery . the levels of t ##ma ##o and its precursor ##s did not differ between obe ##se patients with t ##2 ##dm and non - t ##2 ##dm at baseline . however , t ##ma ##o increased more than two ##fold in patients with t ##2 ##dm after ry ##gb surgery , but not in patients without t ##2 ##dm . cho ##line levels were decreased by half in all patients after ry ##gb . in patients with t ##2 ##dm who underwent sg , t ##ma ##o , beta ##ine , and car ##ni ##tine levels did not change after the surgery . furthermore , in obe ##se patients who underwent bari ##at ##ric surgery , increased t ##ma ##o levels were associated with both t ##2 ##dm and ry ##gb , while reduced cho ##line levels were associated with ry ##gb . these associations need to be further el ##uc ##ida ##ted in follow - up studies to gain further insights into the relationship between t ##ma ##o levels and bari ##at ##ric surgery outcomes . ' ) ] [SEP]
02/24/2023 10:36:26 - INFO - data - input_ids: 101 3431 1999 12241 11031 23943 11233 1011 1050 1011 15772 3798 1999 15578 3366 5022 2206 5001 10464 24895 20996 5602 1011 4372 1011 1061 3806 12412 11826 2030 10353 3806 7913 6593 16940 1999 1037 4759 24552 11707 3949 2817 1006 24113 4757 1007 1012 102 16428 6850 29201 1006 1031 1006 1005 10514 2361 1005 1010 1031 1005 1016 1005 1010 1005 1016 1005 1033 1007 1010 1006 1005 1001 3793 1005 1010 1005 12241 11031 23943 11233 1050 1011 15772 1006 1056 2863 2080 1007 1010 1037 9535 12702 4783 1011 7790 18804 14956 4221 1010 2038 2042 20467 2004 1037 3117 3891 5387 2005 22935 2824 3141 2000 24552 1998 2828 1016 14671 11463 15909 2271 1006 1056 2475 22117 1007 1012 1996 6614 1997 1996 2817 2001 2000 3231 1996 10744 2065 1056 2863 2080 2003 3378 2007 1996 7312 1997 22935 4295 1999 1996 4759 15578 3366 5022 2040 9601 22466 4017 7277 5970 1012 2013 1037 20576 1997 1037 4800 13013 2121 1010 2512 13033 20936 5422 1010 4758 3979 1010 4159 24113 4757 1010 4229 15578 3366 5022 1010 2324 2007 1998 2322 2302 1056 2475 22117 1010 2040 9601 20996 5602 1011 4372 1011 1061 3806 12412 11826 1006 29431 18259 1007 2030 10353 3806 7913 6593 16940 1006 22214 1007 2020 10847 1012 22466 4017 7277 5970 2003 5393 2005 4759 5022 2007 1037 2303 3742 5950 1006 1038 4328 1007 1609 3486 4705 1013 1049 2030 2005 4759 5022 2007 1037 1038 4328 1609 2382 4705 1013 1049 2040 2031 18609 15185 28173 7368 1012 20194 3798 1997 1056 2863 2080 1998 2049 14988 2015 1010 8247 3170 1010 2482 3490 10196 1010 1998 16480 4179 2020 7594 2077 1998 2416 2706 2044 22466 4017 7277 5970 1012 1996 3798 1997 1056 2863 2080 1998 2049 14988 2015 2106 2025 11234 2090 15578 3366 5022 2007 1056 2475 22117 1998 2512 1011 1056 2475 22117 2012 26163 1012 2174 1010 1056 2863 2080 3445 2062 2084 2048 10371 1999 5022 2007 1056 2475 22117 2044 29431 18259 5970 1010 2021 2025 1999 5022 2302 1056 2475 22117 1012 16480 4179 3798 2020 10548 2011 2431 1999 2035 5022 2044 29431 18259 1012 1999 5022 2007 1056 2475 22117 2040 9601 22214 1010 1056 2863 2080 1010 8247 3170 1010 1998 2482 3490 10196 3798 2106 2025 2689 2044 1996 5970 1012 7297 1010 1999 15578 3366 5022 2040 9601 22466 4017 7277 5970 1010 3445 1056 2863 2080 3798 2020 3378 2007 2119 1056 2475 22117 1998 29431 18259 1010 2096 4359 16480 4179 3798 2020 3378 2007 29431 18259 1012 2122 8924 2342 2000 2022 2582 3449 14194 8524 3064 1999 3582 1011 2039 2913 2000 5114 2582 20062 2046 1996 3276 2090 1056 2863 2080 3798 1998 22466 4017 7277 5970 13105 1012 1005 1007 1033 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:26 - INFO - data - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:26 - INFO - data - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:26 - INFO - data - label: diabetes (id = 1)
02/24/2023 10:36:26 - INFO - data - *** Example ***
02/24/2023 10:36:26 - INFO - data - tokens: [CLS] the role of z ##n ##f ##14 ##3 in breast cancer cell survival through the nad ( p ) h qui ##non ##e de ##hy ##dro ##genase 1 ? [UNK] ? [UNK] axis under metabolic stress . [SEP] auto ##pha ##gy is a cellular process that disrupt ##s and uses unnecessary or mal ##fu ##nction ##ing components for cellular home ##osta ##sis . evidence has shown a role for auto ##pha ##gy in tumor cell survival , but the molecular deter ##mina ##nts that define sensitivity against auto ##pha ##gic regulation in cancers are not clear . importantly , we found that breast cancer cells with low expression levels of a zinc - finger protein , z ##n ##f ##14 ##3 ( mc ##f ##7 sh - z ##n ##f ##14 ##3 ) , showed better survival than control cells ( mc ##f ##7 sh - control ) under starvation , which was compromised with ch ##lor ##o ##quin ##e , an auto ##pha ##gy inhibitor . in addition , there were more auto ##pha ##gic ve ##sic ##les in mc ##f ##7 sh - z ##n ##f ##14 ##3 cells than in mc ##f ##7 sh - control cells , and proteins related with the auto ##pha ##gic process , such as be ##cl ##in ##1 , p ##6 ##2 , and at ##gs , were altered in cells with less z ##n ##f ##14 ##3 . z ##n ##f ##14 ##3 knock ##down affected the stability of p ##53 , which showed a dependence on mg ##13 ##2 , a pro ##tea ##some inhibitor . data from pro ##te ##ome prof ##iling in breast cancer cells with less z ##n ##f ##14 ##3 suggest a role of nad ( p ) h qui ##non ##e de ##hy ##dro ##genase 1 ( n ##q ##o ##1 ) for p ##53 stability . taken together , we showed that a subset of breast cancer cells with low expression of z ##n ##f ##14 ##3 might exhibit better survival via an auto ##pha ##gic process by regulating the p ##53 ##⁻ ##be ##cl ##in ##1 axis , co ##rro ##bor ##ating the necessity of blocking auto ##pha ##gy for the best therapy . [SEP]
02/24/2023 10:36:26 - INFO - data - input_ids: 101 1996 2535 1997 1062 2078 2546 16932 2509 1999 7388 4456 3526 7691 2083 1996 23233 1006 1052 1007 1044 21864 8540 2063 2139 10536 22196 28835 1015 1029 100 1029 100 8123 2104 21453 6911 1012 102 8285 21890 6292 2003 1037 12562 2832 2008 23217 2015 1998 3594 14203 2030 15451 11263 27989 2075 6177 2005 12562 2188 28696 6190 1012 3350 2038 3491 1037 2535 2005 8285 21890 6292 1999 13656 3526 7691 1010 2021 1996 8382 28283 22311 7666 2008 9375 14639 2114 8285 21890 12863 7816 1999 25409 2024 2025 3154 1012 14780 1010 2057 2179 2008 7388 4456 4442 2007 2659 3670 3798 1997 1037 15813 1011 4344 5250 1010 1062 2078 2546 16932 2509 1006 11338 2546 2581 14021 1011 1062 2078 2546 16932 2509 1007 1010 3662 2488 7691 2084 2491 4442 1006 11338 2546 2581 14021 1011 2491 1007 2104 22611 1010 2029 2001 20419 2007 10381 10626 2080 12519 2063 1010 2019 8285 21890 6292 24054 1012 1999 2804 1010 2045 2020 2062 8285 21890 12863 2310 19570 4244 1999 11338 2546 2581 14021 1011 1062 2078 2546 16932 2509 4442 2084 1999 11338 2546 2581 14021 1011 2491 4442 1010 1998 8171 3141 2007 1996 8285 21890 12863 2832 1010 2107 2004 2022 20464 2378 2487 1010 1052 2575 2475 1010 1998 2012 5620 1010 2020 8776 1999 4442 2007 2625 1062 2078 2546 16932 2509 1012 1062 2078 2546 16932 2509 7324 7698 5360 1996 9211 1997 1052 22275 1010 2029 3662 1037 18642 2006 11460 17134 2475 1010 1037 4013 27058 14045 24054 1012 2951 2013 4013 2618 8462 11268 16281 1999 7388 4456 4442 2007 2625 1062 2078 2546 16932 2509 6592 1037 2535 1997 23233 1006 1052 1007 1044 21864 8540 2063 2139 10536 22196 28835 1015 1006 1050 4160 2080 2487 1007 2005 1052 22275 9211 1012 2579 2362 1010 2057 3662 2008 1037 16745 1997 7388 4456 4442 2007 2659 3670 1997 1062 2078 2546 16932 2509 2453 8327 2488 7691 3081 2019 8285 21890 12863 2832 2011 21575 1996 1052 22275 30079 4783 20464 2378 2487 8123 1010 2522 18933 12821 5844 1996 13185 1997 10851 8285 21890 6292 2005 1996 2190 7242 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:26 - INFO - data - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:26 - INFO - data - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/24/2023 10:36:26 - INFO - data - label: x (id = 5)
02/24/2023 10:36:27 - INFO - __main__ - shape of the train set: (4514, 4)
02/24/2023 10:36:27 - INFO - __main__ - shape of the dev set: (564, 4)

02/24/2023 10:36:27 - INFO - __main__ - ======================================================================
02/24/2023 10:36:27 - INFO - __main__ - [Epoch 1/50]
02/24/2023 10:39:05 - INFO - __main__ - ****** Train result ******   loss : 1.026, accuracy : 0.659
02/24/2023 10:39:12 - INFO - __main__ - ****** Validation result ******   loss : 0.680, accuracy : 0.785
02/24/2023 10:39:12 - INFO - __main__ - ======================================================================
02/24/2023 10:39:13 - INFO - __main__ - [Epoch 2/50]
02/24/2023 10:40:58 - INFO - __main__ - ****** Train result ******   loss : 0.538, accuracy : 0.825
02/24/2023 10:41:05 - INFO - __main__ - ****** Validation result ******   loss : 0.600, accuracy : 0.793
02/24/2023 10:41:05 - INFO - __main__ - ======================================================================
02/24/2023 10:41:06 - INFO - __main__ - [Epoch 3/50]
02/24/2023 10:42:50 - INFO - __main__ - ****** Train result ******   loss : 0.406, accuracy : 0.871
02/24/2023 10:42:57 - INFO - __main__ - ****** Validation result ******   loss : 0.588, accuracy : 0.805
02/24/2023 10:42:57 - INFO - __main__ - ======================================================================
02/24/2023 10:42:59 - INFO - __main__ - [Epoch 4/50]
02/24/2023 10:44:43 - INFO - __main__ - ****** Train result ******   loss : 0.320, accuracy : 0.896
02/24/2023 10:44:50 - INFO - __main__ - ****** Validation result ******   loss : 0.533, accuracy : 0.821
02/24/2023 10:44:50 - INFO - __main__ - ======================================================================
02/24/2023 10:44:51 - INFO - __main__ - [Epoch 5/50]
02/24/2023 10:46:36 - INFO - __main__ - ****** Train result ******   loss : 0.230, accuracy : 0.927
02/24/2023 10:46:43 - INFO - __main__ - ****** Validation result ******   loss : 0.566, accuracy : 0.833
02/24/2023 10:46:43 - INFO - __main__ - ======================================================================
02/24/2023 10:46:44 - INFO - __main__ - [Epoch 6/50]
02/24/2023 10:48:29 - INFO - __main__ - ****** Train result ******   loss : 0.174, accuracy : 0.945
02/24/2023 10:48:36 - INFO - __main__ - ****** Validation result ******   loss : 0.605, accuracy : 0.837
02/24/2023 10:48:36 - INFO - __main__ - ======================================================================
02/24/2023 10:48:37 - INFO - __main__ - [Epoch 7/50]
02/24/2023 10:50:22 - INFO - __main__ - ****** Train result ******   loss : 0.123, accuracy : 0.963
02/24/2023 10:50:29 - INFO - __main__ - ****** Validation result ******   loss : 0.696, accuracy : 0.823
02/24/2023 10:50:29 - INFO - __main__ - ======================================================================
02/24/2023 10:50:29 - INFO - __main__ - [Epoch 8/50]
02/24/2023 10:52:15 - INFO - __main__ - ****** Train result ******   loss : 0.098, accuracy : 0.971
02/24/2023 10:52:22 - INFO - __main__ - ****** Validation result ******   loss : 0.711, accuracy : 0.832
02/24/2023 10:52:22 - INFO - __main__ - ======================================================================
02/24/2023 10:52:22 - INFO - __main__ - [Epoch 9/50]
02/24/2023 10:54:07 - INFO - __main__ - ****** Train result ******   loss : 0.067, accuracy : 0.979
02/24/2023 10:54:14 - INFO - __main__ - ****** Validation result ******   loss : 0.825, accuracy : 0.833
02/24/2023 10:54:14 - INFO - __main__ - ======================================================================
02/24/2023 10:54:14 - INFO - __main__ - [Epoch 10/50]
02/24/2023 10:56:53 - INFO - __main__ - ****** Train result ******   loss : 0.045, accuracy : 0.987
02/24/2023 10:57:00 - INFO - __main__ - ****** Validation result ******   loss : 0.842, accuracy : 0.830
02/24/2023 10:57:00 - INFO - __main__ - ======================================================================
02/24/2023 10:57:00 - INFO - __main__ - [Epoch 11/50]
02/24/2023 10:58:44 - INFO - __main__ - ****** Train result ******   loss : 0.037, accuracy : 0.988
02/24/2023 10:58:51 - INFO - __main__ - ****** Validation result ******   loss : 1.030, accuracy : 0.796
02/24/2023 10:58:51 - INFO - __main__ - ======================================================================
02/24/2023 10:58:51 - INFO - __main__ - [Epoch 12/50]
02/24/2023 11:00:36 - INFO - __main__ - ****** Train result ******   loss : 0.025, accuracy : 0.994
02/24/2023 11:00:44 - INFO - __main__ - ****** Validation result ******   loss : 1.057, accuracy : 0.810
02/24/2023 11:00:44 - INFO - __main__ - ======================================================================
02/24/2023 11:00:44 - INFO - __main__ - [Epoch 13/50]
02/24/2023 11:02:28 - INFO - __main__ - ****** Train result ******   loss : 0.016, accuracy : 0.997
02/24/2023 11:02:35 - INFO - __main__ - ****** Validation result ******   loss : 0.961, accuracy : 0.842
02/24/2023 11:02:35 - INFO - __main__ - ======================================================================
02/24/2023 11:02:36 - INFO - __main__ - [Epoch 14/50]
02/24/2023 11:04:21 - INFO - __main__ - ****** Train result ******   loss : 0.018, accuracy : 0.994
02/24/2023 11:04:28 - INFO - __main__ - ****** Validation result ******   loss : 1.116, accuracy : 0.819
02/24/2023 11:04:28 - INFO - __main__ - ======================================================================
02/24/2023 11:04:28 - INFO - __main__ - [Epoch 15/50]
02/24/2023 11:06:12 - INFO - __main__ - ****** Train result ******   loss : 0.013, accuracy : 0.997
02/24/2023 11:06:19 - INFO - __main__ - ****** Validation result ******   loss : 1.034, accuracy : 0.833
02/24/2023 11:06:19 - INFO - __main__ - ======================================================================
02/24/2023 11:06:19 - INFO - __main__ - [Epoch 16/50]
02/24/2023 11:08:04 - INFO - __main__ - ****** Train result ******   loss : 0.013, accuracy : 0.997
02/24/2023 11:08:12 - INFO - __main__ - ****** Validation result ******   loss : 1.125, accuracy : 0.830
02/24/2023 11:08:12 - INFO - __main__ - ======================================================================
02/24/2023 11:08:12 - INFO - __main__ - [Epoch 17/50]
02/24/2023 11:09:56 - INFO - __main__ - ****** Train result ******   loss : 0.009, accuracy : 0.998
02/24/2023 11:10:03 - INFO - __main__ - ****** Validation result ******   loss : 1.155, accuracy : 0.816
02/24/2023 11:10:03 - INFO - __main__ - ======================================================================
02/24/2023 11:10:03 - INFO - __main__ - [Epoch 18/50]
02/24/2023 11:11:47 - INFO - __main__ - ****** Train result ******   loss : 0.007, accuracy : 0.998
02/24/2023 11:11:54 - INFO - __main__ - ****** Validation result ******   loss : 1.136, accuracy : 0.826
02/24/2023 11:11:54 - INFO - __main__ - ======================================================================
02/24/2023 11:11:54 - INFO - __main__ - [Epoch 19/50]
02/24/2023 11:13:38 - INFO - __main__ - ****** Train result ******   loss : 0.009, accuracy : 0.997
02/24/2023 11:13:45 - INFO - __main__ - ****** Validation result ******   loss : 1.206, accuracy : 0.809
02/24/2023 11:13:45 - INFO - __main__ - ======================================================================
02/24/2023 11:13:45 - INFO - __main__ - [Epoch 20/50]
02/24/2023 11:16:19 - INFO - __main__ - ****** Train result ******   loss : 0.008, accuracy : 0.997
02/24/2023 11:16:26 - INFO - __main__ - ****** Validation result ******   loss : 1.230, accuracy : 0.819
02/24/2023 11:16:26 - INFO - __main__ - ======================================================================
02/24/2023 11:16:26 - INFO - __main__ - [Epoch 21/50]
02/24/2023 11:18:10 - INFO - __main__ - ****** Train result ******   loss : 0.004, accuracy : 0.998
02/24/2023 11:18:17 - INFO - __main__ - ****** Validation result ******   loss : 1.226, accuracy : 0.819
02/24/2023 11:18:17 - INFO - __main__ - ======================================================================
02/24/2023 11:18:17 - INFO - __main__ - [Epoch 22/50]
02/24/2023 11:20:01 - INFO - __main__ - ****** Train result ******   loss : 0.007, accuracy : 0.998
02/24/2023 11:20:08 - INFO - __main__ - ****** Validation result ******   loss : 1.196, accuracy : 0.826
02/24/2023 11:20:08 - INFO - __main__ - ======================================================================
02/24/2023 11:20:08 - INFO - __main__ - [Epoch 23/50]
02/24/2023 11:21:51 - INFO - __main__ - ****** Train result ******   loss : 0.006, accuracy : 0.998
02/24/2023 11:21:58 - INFO - __main__ - ****** Validation result ******   loss : 1.309, accuracy : 0.821
02/24/2023 11:21:58 - INFO - __main__ - ======================================================================
02/24/2023 11:21:58 - INFO - __main__ - [Epoch 24/50]
02/24/2023 11:23:43 - INFO - __main__ - ****** Train result ******   loss : 0.004, accuracy : 0.998
02/24/2023 11:23:50 - INFO - __main__ - ****** Validation result ******   loss : 1.257, accuracy : 0.828
02/24/2023 11:23:50 - INFO - __main__ - ======================================================================
02/24/2023 11:23:50 - INFO - __main__ - [Epoch 25/50]
02/24/2023 11:25:35 - INFO - __main__ - ****** Train result ******   loss : 0.003, accuracy : 0.999
02/24/2023 11:25:42 - INFO - __main__ - ****** Validation result ******   loss : 1.304, accuracy : 0.826
02/24/2023 11:25:42 - INFO - __main__ - ======================================================================
02/24/2023 11:25:42 - INFO - __main__ - [Epoch 26/50]
02/24/2023 11:27:27 - INFO - __main__ - ****** Train result ******   loss : 0.004, accuracy : 0.998
02/24/2023 11:27:34 - INFO - __main__ - ****** Validation result ******   loss : 1.317, accuracy : 0.824
02/24/2023 11:27:34 - INFO - __main__ - ======================================================================
02/24/2023 11:27:34 - INFO - __main__ - [Epoch 27/50]
02/24/2023 11:29:19 - INFO - __main__ - ****** Train result ******   loss : 0.004, accuracy : 0.998
02/24/2023 11:29:26 - INFO - __main__ - ****** Validation result ******   loss : 1.262, accuracy : 0.823
02/24/2023 11:29:26 - INFO - __main__ - ======================================================================
02/24/2023 11:29:26 - INFO - __main__ - [Epoch 28/50]
02/24/2023 11:31:10 - INFO - __main__ - ****** Train result ******   loss : 0.003, accuracy : 0.998
02/24/2023 11:31:17 - INFO - __main__ - ****** Validation result ******   loss : 1.280, accuracy : 0.832
02/24/2023 11:31:17 - INFO - __main__ - ======================================================================
02/24/2023 11:31:17 - INFO - __main__ - [Epoch 29/50]
02/24/2023 11:33:00 - INFO - __main__ - ****** Train result ******   loss : 0.003, accuracy : 0.999
02/24/2023 11:33:07 - INFO - __main__ - ****** Validation result ******   loss : 1.272, accuracy : 0.830
02/24/2023 11:33:07 - INFO - __main__ - ======================================================================
02/24/2023 11:33:07 - INFO - __main__ - [Epoch 30/50]
02/24/2023 11:35:41 - INFO - __main__ - ****** Train result ******   loss : 0.003, accuracy : 0.998
02/24/2023 11:35:48 - INFO - __main__ - ****** Validation result ******   loss : 1.212, accuracy : 0.839
02/24/2023 11:35:48 - INFO - __main__ - ======================================================================
02/24/2023 11:35:48 - INFO - __main__ - [Epoch 31/50]
02/24/2023 11:37:32 - INFO - __main__ - ****** Train result ******   loss : 0.003, accuracy : 0.998
02/24/2023 11:37:39 - INFO - __main__ - ****** Validation result ******   loss : 1.290, accuracy : 0.816
02/24/2023 11:37:39 - INFO - __main__ - ======================================================================
02/24/2023 11:37:39 - INFO - __main__ - [Epoch 32/50]
02/24/2023 11:39:22 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.998
02/24/2023 11:39:29 - INFO - __main__ - ****** Validation result ******   loss : 1.252, accuracy : 0.840
02/24/2023 11:39:29 - INFO - __main__ - ======================================================================
02/24/2023 11:39:29 - INFO - __main__ - [Epoch 33/50]
02/24/2023 11:41:13 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.999
02/24/2023 11:41:20 - INFO - __main__ - ****** Validation result ******   loss : 1.347, accuracy : 0.824
02/24/2023 11:41:20 - INFO - __main__ - ======================================================================
02/24/2023 11:41:20 - INFO - __main__ - [Epoch 34/50]
02/24/2023 11:43:03 - INFO - __main__ - ****** Train result ******   loss : 0.003, accuracy : 0.998
02/24/2023 11:43:10 - INFO - __main__ - ****** Validation result ******   loss : 1.388, accuracy : 0.824
02/24/2023 11:43:10 - INFO - __main__ - ======================================================================
02/24/2023 11:43:10 - INFO - __main__ - [Epoch 35/50]
02/24/2023 11:44:54 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.999
02/24/2023 11:45:01 - INFO - __main__ - ****** Validation result ******   loss : 1.302, accuracy : 0.832
02/24/2023 11:45:01 - INFO - __main__ - ======================================================================
02/24/2023 11:45:01 - INFO - __main__ - [Epoch 36/50]
02/24/2023 11:46:44 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.999
02/24/2023 11:46:51 - INFO - __main__ - ****** Validation result ******   loss : 1.448, accuracy : 0.819
02/24/2023 11:46:51 - INFO - __main__ - ======================================================================
02/24/2023 11:46:51 - INFO - __main__ - [Epoch 37/50]
02/24/2023 11:48:35 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.999
02/24/2023 11:48:42 - INFO - __main__ - ****** Validation result ******   loss : 1.357, accuracy : 0.830
02/24/2023 11:48:42 - INFO - __main__ - ======================================================================
02/24/2023 11:48:42 - INFO - __main__ - [Epoch 38/50]
02/24/2023 11:50:25 - INFO - __main__ - ****** Train result ******   loss : 0.004, accuracy : 0.998
02/24/2023 11:50:32 - INFO - __main__ - ****** Validation result ******   loss : 1.385, accuracy : 0.828
02/24/2023 11:50:32 - INFO - __main__ - ======================================================================
02/24/2023 11:50:32 - INFO - __main__ - [Epoch 39/50]
02/24/2023 11:52:16 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.999
02/24/2023 11:52:23 - INFO - __main__ - ****** Validation result ******   loss : 1.367, accuracy : 0.833
02/24/2023 11:52:23 - INFO - __main__ - ======================================================================
02/24/2023 11:52:23 - INFO - __main__ - [Epoch 40/50]
02/24/2023 11:54:57 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.998
02/24/2023 11:55:04 - INFO - __main__ - ****** Validation result ******   loss : 1.344, accuracy : 0.830
02/24/2023 11:55:04 - INFO - __main__ - ======================================================================
02/24/2023 11:55:04 - INFO - __main__ - [Epoch 41/50]
02/24/2023 11:56:47 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.999
02/24/2023 11:56:54 - INFO - __main__ - ****** Validation result ******   loss : 1.329, accuracy : 0.828
02/24/2023 11:56:54 - INFO - __main__ - ======================================================================
02/24/2023 11:56:54 - INFO - __main__ - [Epoch 42/50]
02/24/2023 11:58:38 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.998
02/24/2023 11:58:45 - INFO - __main__ - ****** Validation result ******   loss : 1.422, accuracy : 0.826
02/24/2023 11:58:45 - INFO - __main__ - ======================================================================
02/24/2023 11:58:45 - INFO - __main__ - [Epoch 43/50]
02/24/2023 12:00:28 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.998
02/24/2023 12:00:35 - INFO - __main__ - ****** Validation result ******   loss : 1.383, accuracy : 0.832
02/24/2023 12:00:35 - INFO - __main__ - ======================================================================
02/24/2023 12:00:35 - INFO - __main__ - [Epoch 44/50]
02/24/2023 12:02:19 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.999
02/24/2023 12:02:26 - INFO - __main__ - ****** Validation result ******   loss : 1.383, accuracy : 0.832
02/24/2023 12:02:26 - INFO - __main__ - ======================================================================
02/24/2023 12:02:26 - INFO - __main__ - [Epoch 45/50]
02/24/2023 12:04:09 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.998
02/24/2023 12:04:16 - INFO - __main__ - ****** Validation result ******   loss : 1.420, accuracy : 0.826
02/24/2023 12:04:16 - INFO - __main__ - ======================================================================
02/24/2023 12:04:16 - INFO - __main__ - [Epoch 46/50]
02/24/2023 12:06:00 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.998
02/24/2023 12:06:07 - INFO - __main__ - ****** Validation result ******   loss : 1.411, accuracy : 0.830
02/24/2023 12:06:07 - INFO - __main__ - ======================================================================
02/24/2023 12:06:07 - INFO - __main__ - [Epoch 47/50]
02/24/2023 12:07:50 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.998
02/24/2023 12:07:57 - INFO - __main__ - ****** Validation result ******   loss : 1.406, accuracy : 0.826
02/24/2023 12:07:57 - INFO - __main__ - ======================================================================
02/24/2023 12:07:57 - INFO - __main__ - [Epoch 48/50]
02/24/2023 12:09:41 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.999
02/24/2023 12:09:48 - INFO - __main__ - ****** Validation result ******   loss : 1.429, accuracy : 0.824
02/24/2023 12:09:48 - INFO - __main__ - ======================================================================
02/24/2023 12:09:48 - INFO - __main__ - [Epoch 49/50]
02/24/2023 12:11:31 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.999
02/24/2023 12:11:38 - INFO - __main__ - ****** Validation result ******   loss : 1.424, accuracy : 0.826
02/24/2023 12:11:38 - INFO - __main__ - ======================================================================
02/24/2023 12:11:38 - INFO - __main__ - [Epoch 50/50]
02/24/2023 12:14:12 - INFO - __main__ - ****** Train result ******   loss : 0.002, accuracy : 0.999
02/24/2023 12:14:19 - INFO - __main__ - ****** Validation result ******   loss : 1.422, accuracy : 0.826
02/24/2023 12:14:19 - INFO - __main__ - ======================================================================
02/24/2023 12:14:19 - INFO - __main__ - Training took 1:37:52.522291
02/24/2023 12:14:20 - INFO - __main__ - Best Epoch: 13
02/24/2023 12:14:20 - INFO - __main__ - Best Accuracy: 0.842
02/24/2023 12:14:27 - INFO - __main__ - ======================================================================
02/24/2023 12:14:27 - INFO - __main__ - Classification Report
02/24/2023 12:14:27 - INFO - __main__ - 
              precision    recall  f1-score   support

        bone       0.81      0.84      0.83        62
    diabetes       0.85      0.93      0.89       201
      others       0.71      0.43      0.54        46
pitu/adrenal       0.73      0.70      0.71        23
     thyroid       0.98      0.97      0.97        87
           x       0.81      0.80      0.80       145

    accuracy                           0.84       564
   macro avg       0.81      0.78      0.79       564
weighted avg       0.84      0.84      0.84       564


02/24/2023 12:14:27 - INFO - __main__ - ======================================================================
02/24/2023 12:14:27 - INFO - __main__ - Accuracy on the Validation set: 0.842
02/24/2023 12:14:27 - INFO - __main__ - ======================================================================
